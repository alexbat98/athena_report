\clearpage

\section{Детальный обзор Tensorflow}

\subsection{Основные понятия}

В TensorFlow вычисления описываются с помощью графа вычислений (англ.
\textit{computation graph}), который состоит из набора вершин (англ.
\textit{nodes}). У каждой вершины 0 или более входов и 0 или более выходов,
и с каждой вершиной связана операция (англ. \textit{operation}). Значения,
передающиеся по ребрам графа, называются тензорами (англ. \textit{tensor}).
Тензор -- массив произвольной размерности с определенным типом данных элемента.
Кроме того, существуют специальные ребра, называемые зависимостями управления
(англ. \textit{control dependencies}). По ним не передаются данные, но они
показывают, что родительские вершины должны завершить вычисления раньше потомков.

Каждой операции соответствуют имя и абстрактные вычисления (например, умножение
матриц). У операции могут быть атрибуты, значения которых должны быть
предоставлены во время построения графа. Ядром (англ. \textit{kernel}) называют
конкретную реализацию вычислений для определенного класса устройств.

Клиентские программы взаимодействуют с TensorFlow посредством создания сессии
(англ. \textit{session}). Главный метод объекта сессии -- \textbf{Run}. Он
принимает в качестве входных значений имена вершин, значения которых необходимо
вычислить, а так же необходимые для вычисления графа аргументы. Используя эти
данные, TensorFlow может вычислить транзитивное замыкание, содержащее все
вершины, выполнение которых необходимо для получения результата.

Часто граф исполняется несколько раз. Большинство тензоров уничтожается после
исполнения графа. Однако, особый вид операций, называемых переменными (англ.
\textit{variables}), позволяет создать тензоры, которые сохранят свое значение
после исполнения графа.

\subsection{Реализация вычислений}

\subsubsection{Вычисления на графе}

Главными компонентами TensorFlow являются клиент, который использует сессию
для взаимодействия с мастером (англ. \textit{master}), и один или более
рабочих процессов (англ. \textit{worker processes}). Каждый рабочий процесс
управляет одним или более устройством и по указанию мастера исполняет вершины.
Существуют локальная и распределенная реализации интерфейса TensorFlow.
Локальная применяется в том случае, когда мастер, клиент и рабочий процесс
находятся на одной машине. Распределенная позволяет работать в окружении,
состоящем из нескольких машин.

В случае окружения с одним вычислительным устройством оно последовательно
выполняет все вершины с учетом их зависимостей. В частности, каждая
неисполненная вершина хранит счетчик неудовлетворенных зависимостей. Как только
он достигает нулевого значения, вершина добавляется в очередь на исполнение.
По завершении исполнения вершина уменьшает счетчики зависимых вершин на 1.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{tf_dev.png}
    \caption{Схема работы TensorFlow с одной и несколькими машинами}
    \label{fig:tf_dev}
\end{figure}

При наличии нескольких вычислительных устройств появляется ряд проблем: принятие
решения о целевом устройстве для каждой вершины, коммуникация между устройствами.

Алгоритм, принимающий решение о размещении вершины на устройстве, учитывает
модель стоимости операций, которая оценивает время исполнения алгоритма и
объем требуемой памяти. Эта модель строится либо на основе эвристик, либо
по результатам предыдущих вычислений. Алгоритм размещения производит симуляцию
вычислений на графе, начиная во входных вершинах и продвигаясь вглубь. Для
каждой вершины, которая рассматривается алгоритмом, определяется список устройств,
на которых она может быть исполнена. В случае, если устройств больше 1,
используется жадный алгоритм, определяющий наиболее подходящее устройство.
Подробнее эти механизмы описаны в разделах 3.2.1 и 4.6 \cite{tf}.

По окончании размещения вершин происходит деление графа на подграфы. Каждый
подграф выполняется на 1 устройстве. Для обеспечения коммуникации между
устройствами, на границах подграфов вставляются служебные вершины передачи и
приема (англ. \textit{send and receive nodes}).

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{tf_graph_partition}
    \caption{Граф до и после деления на подграфы}
    \label{fig:tf_graph_partition}
\end{figure}

\subsubsection{Вычисление градиента на графе}

В TensorFlow реализована поддержка автоматического вычисления градиента функции.
Градиент вычисляется так же, как и любые другие функции, путем вычислений на
графе. Для построения необходимого графа используется следующая процедура.

Когда TensorFlow необходимо вычислить градиент тензора $C$ по некоторому
тензору $I$, от которого $C$ зависит, фреймворк сперва находит путь из
$I$ в $C$. Затем, начиная с конца этого пути (то есть из вершины, содержащей $C$),
библиотека добавляет в граф вершину, вычисляющую частную производную,
руководствуясь правилом дифференцирования сложной функции. Каждая операция сама
определяет правила собственного дифференцирования.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{tf_autograd}
    \caption{Работа алгоритма автоматического дифференцирования}
    \label{fig:tf_autograd}
\end{figure}

В общем случае, у операции может быть несколько выходов, а $C$ может зависеть
только от некоторых из них.

Автоматическое дифференцирование затрудняет работу оптимизационных процедур,
в частности анализ расхода памяти. У пользователя отсутствует возможность
управлять автоматически сгенерированной частью графа. Поскольку градиентные
вершины меняют направление вычислений, тензоры, которые использовались в начале,
зачастую требуются в конце. Это сильно ограничивает размер возможных вычислений,
в особенности на GPU.

% todo:
% 1) 4.2 Partial execution
% 2) 4.4 Control flow
% 3) 4.5 Input operations
% 4) 5 Optimizations
