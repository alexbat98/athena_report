\clearpage
\section{Постановка задачи}
Структуру фреймворка можно разделить на Backend и Core. Core - ядро фреймворка. Главная его часть - граф вычислений (Graph). В рамках данной работы под графом вычислений будет пониматься направленный ациклический граф. Он состоит из множества вершин (Node). Вершина может содержать операции (Operation) или тензоры (Tensor). Под тензором будет пониматься многомерный массив, для которого заданы набор размеров каждого измерения (Shape) и тип данных (Data type). Тензор является единицей информации в графе. Каждая операция принимает ноль и более тензоров и возвращает ноль и более тензоров. Таким образом, граф представляет собой функцию многих переменных, для которой необходимо найти глобальный минимум. Ядро - центральный компонент фреймворка, обеспечивающий взаимодействие с остальными частями. 
\par
Backend представляет собой абстрактную виртуальную машину. С ее помощью будет исполняться граф вычислений. Фреймворк будет содержать несколько различных виртуальных машин, но все они должны удовлетворять ряду требований. Во-первых, все виртуальные машины должны поддерживать виртуальное адресное пространство (ВАП) на основе линейной модели памяти. Адрес в ВАП является натуральным числом из отрезка [1, $2^{64}-1$]. Адрес 0 является зарезервированным. Распределением памяти в ВАП, а также трансляцией виртуальных адресов фреймворка в реальные\footnote{Под реальными понимаются адреса, характерные для устройства памяти. Например, для оперативной памяти это будет виртуальный адрес из ВАП приложения, который затем будет преобразован в физический адрес средствами ОС.} занимается аллокатор (Allocator). Аллокатор может инкапсулировать в себе механизмы взаимодействия с физической памятью (например, с оперативной памятью или памятью видеокарты), управления подкачкой, распределения виртуальных адресов. У виртуальной машины может быть более одного аллокатора. Например, обучение производится на выделенном сервере, значит, можно использовать всю доступную оперативную память. А исполнение -- на домашнем компьютере пользователя, значит потребление ОЗУ не должно быть чрезмерным. Для этих целей имеет смысл создать два различных аллокатора.
\par
Непосредственно выполнением графа будет заниматься исполнитель (Executor). С помощью генератора он будет получать всю необходимую для исполнения. Он также отвечает за работу с многопоточностью.
В качестве первой виртуальной машины будет использоваться LLVM — универсальная система анализа, трансформации и оптимизации программ, реализующая виртуальную машину с RISC-подобными инструкциями. Может использоваться как оптимизирующий компилятор байткода в машинный код для различных архитектур либо для его интерпретации и JIT-компиляции (для некоторых платформ). 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.75\textwidth]{llvm}
	\caption{Структура компилятора LLVM}
	\label{task:llvm}
\end{figure}
\par
Типичный компилятор на основе LLVM делает лексический разбор исходного кода, строит абстрактное синтаксическое дерево (Abstract Syntax Tree, AST), а затем генерирует LLVM IR - специальное промежуточное представление, которое позже будет преобразовано в машинный код. В случае фреймворка, в качестве AST может выступать граф вычислений. Таким образом, большая часть работы оказывается выполненной. 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{ast}
	\caption{Абстрактное синтаксическое дерево}
	\label{task:ast}
\end{figure}
%\begin{lstlisting} 
while b != 0
    if a > b
        a := a − b
    else
        b := b − a
return a
%\end{lstlisting}
\par
Использование LLVM даст следующие преимущества:
\begin{enumerate}
	\item Быстрая среда исполнения. LLVM позволяет скомпилировать байткод, что дает прирост производительности по сравнению с исполнением графа во время обхода. 
	\item Оптимизации. В LLVM встроено множество инструментов для низкоуровневых оптимизаций байткода.
	\item Возможность создать исполняемый файл, который будет содержать только граф вычислений. Это позволит эффективно встраивать обученную модель в пользовательские приложения.
\end{enumerate}
\par
	Одновременное обучение на нескольких устройствах останется перспективой на будущее и не будет рассматриваться в рамках данной работы.

